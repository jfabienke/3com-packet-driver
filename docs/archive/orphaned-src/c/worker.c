/**
 * @file worker.c
 * @brief Bottom-half worker for deferred interrupt processing
 * 
 * Processes work items generated by the tiny ISR in batches to maximize
 * performance while maintaining low latency.
 */

#include <stdint.h>
#include <string.h>
#include <stdbool.h>
#include "worker.h"
#include "workqueue.h"
#include "packet_ops.h"
#include "hardware.h"
#include "logging.h"
#include "stats.h"

/* Worker configuration */
#define MAX_WORK_BUDGET     32      /* Max work items per call */
#define MAX_TIME_BUDGET     1000    /* Max microseconds per call */
#define RX_BATCH_THRESHOLD  16      /* Start batching after N packets */
#define TX_BATCH_THRESHOLD  8       /* TX completion batching */

/* Worker state */
struct worker_state {
    uint32_t total_processed;       /* Total work items processed */
    uint32_t rx_processed;          /* RX packets processed */
    uint32_t tx_processed;          /* TX completions processed */
    uint32_t errors_processed;      /* Error conditions processed */
    uint32_t budget_exceeded;       /* Times budget was exceeded */
    uint32_t empty_polls;           /* Polls with no work */
    uint16_t max_burst_size;        /* Largest work burst processed */
    uint16_t avg_burst_size;        /* Average work burst size */
};

static struct worker_state worker_stats = {0};

/* Forward declarations for device handlers */
extern int handle_rx_packet(uint8_t device_id, uint16_t length, void *buffer);
extern int handle_tx_complete(uint8_t device_id, uint16_t descriptor_id);
extern int handle_device_error(uint8_t device_id, uint16_t error_code, uint32_t error_data);

/* Buffer management for copy-break */
extern void *get_small_buffer(void);
extern void free_small_buffer(void *buffer);
extern int schedule_rx_refill(uint8_t device_id);

/**
 * Process work for a single device with budget
 * Returns number of work items processed
 */
static int process_device_work(uint8_t device_id, int budget)
{
    work_item_t item;
    int processed = 0;
    int rx_batch = 0;
    int tx_batch = 0;
    
    while (budget > 0 && workqueue_dequeue(device_id, &item)) {
        switch (item.type) {
            case 1: /* WORK_RX_PACKET */
                /* Process RX packet */
                if (handle_rx_packet(device_id, item.data1, item.ptr) == 0) {
                    worker_stats.rx_processed++;
                    rx_batch++;
                }
                break;
                
            case 2: /* WORK_TX_COMPLETE */
                /* Process TX completion */
                if (handle_tx_complete(device_id, item.data1) == 0) {
                    worker_stats.tx_processed++;
                    tx_batch++;
                }
                break;
                
            case 3: /* WORK_ERROR */
                /* Process error condition */
                handle_device_error(device_id, item.data1, item.data2);
                worker_stats.errors_processed++;
                break;
                
            case 4: /* WORK_STATS */
                /* Update statistics (low priority) */
                update_device_stats(device_id);
                break;
                
            default:
                /* Unknown work type - log and ignore */
                LOG_DEBUG("Unknown work type %u from device %u", 
                         item.type, device_id);
                break;
        }
        
        processed++;
        budget--;
        worker_stats.total_processed++;
    }
    
    /* Schedule batch operations if thresholds reached */
    if (rx_batch >= RX_BATCH_THRESHOLD) {
        schedule_rx_refill(device_id);
    }
    
    /* Update burst statistics */
    if (processed > worker_stats.max_burst_size) {
        worker_stats.max_burst_size = processed;
    }
    
    if (processed > 0) {
        /* Update running average (simple exponential moving average) */
        worker_stats.avg_burst_size = 
            (worker_stats.avg_burst_size * 7 + processed) / 8;
    }
    
    return processed;
}

/**
 * Main worker entry point - process all pending work
 * This should be called regularly from the main loop
 */
int worker_process_all(void)
{
    int total_processed = 0;
    int budget = MAX_WORK_BUDGET;
    bool work_found = false;
    
    /* Process work from all devices with shared budget */
    for (uint8_t device_id = 0; device_id < 4 && budget > 0; device_id++) {
        if (workqueue_has_work(device_id)) {
            int processed = process_device_work(device_id, budget);
            total_processed += processed;
            budget -= processed;
            work_found = true;
        }
    }
    
    if (!work_found) {
        worker_stats.empty_polls++;
    }
    
    if (budget == 0) {
        worker_stats.budget_exceeded++;
    }
    
    return total_processed;
}

/**
 * Process work for a specific device only
 */
int worker_process_device(uint8_t device_id)
{
    if (!workqueue_has_work(device_id)) {
        worker_stats.empty_polls++;
        return 0;
    }
    
    return process_device_work(device_id, MAX_WORK_BUDGET);
}

/**
 * Priority worker - process high priority work only
 * Used when system is under load
 */
int worker_process_priority(void)
{
    work_item_t item;
    int processed = 0;
    int budget = MAX_WORK_BUDGET / 2;  /* Smaller budget for priority */
    
    /* Process only RX and error work (skip TX completions and stats) */
    for (uint8_t device_id = 0; device_id < 4 && budget > 0; device_id++) {
        while (budget > 0 && workqueue_dequeue(device_id, &item)) {
            switch (item.type) {
                case 1: /* WORK_RX_PACKET - high priority */
                    if (handle_rx_packet(device_id, item.data1, item.ptr) == 0) {
                        worker_stats.rx_processed++;
                        processed++;
                    }
                    budget--;
                    break;
                    
                case 3: /* WORK_ERROR - high priority */
                    handle_device_error(device_id, item.data1, item.data2);
                    worker_stats.errors_processed++;
                    processed++;
                    budget--;
                    break;
                    
                default:
                    /* Put low priority work back - this is hacky but works */
                    /* In a real implementation, we'd have priority queues */
                    budget = 0;  /* Stop processing this device */
                    break;
            }
        }
    }
    
    worker_stats.total_processed += processed;
    return processed;
}

/**
 * Adaptive worker - adjusts behavior based on load
 */
int worker_process_adaptive(void)
{
    /* Check system load */
    uint8_t max_utilization = 0;
    for (uint8_t device_id = 0; device_id < 4; device_id++) {
        uint8_t util = workqueue_utilization(device_id);
        if (util > max_utilization) {
            max_utilization = util;
        }
    }
    
    /* Adjust processing strategy based on load */
    if (max_utilization > 80) {
        /* High load - priority processing only */
        return worker_process_priority();
    } else if (max_utilization > 50) {
        /* Medium load - reduced budget */
        int total_processed = 0;
        int budget = MAX_WORK_BUDGET / 2;
        
        for (uint8_t device_id = 0; device_id < 4 && budget > 0; device_id++) {
            if (workqueue_has_work(device_id)) {
                int processed = process_device_work(device_id, budget / 2);
                total_processed += processed;
                budget -= processed;
            }
        }
        
        return total_processed;
    } else {
        /* Normal load - full processing */
        return worker_process_all();
    }
}

/**
 * Batch processing optimizations
 */

/**
 * Process RX packets in batch for better cache locality
 */
static int process_rx_batch(uint8_t device_id, int max_packets)
{
    work_item_t rx_items[16];  /* Local batch buffer */
    int batch_size = 0;
    int processed = 0;
    work_item_t item;
    
    /* Collect RX work items */
    while (batch_size < 16 && batch_size < max_packets && 
           workqueue_dequeue(device_id, &item)) {
        
        if (item.type == 1) {  /* WORK_RX_PACKET */
            rx_items[batch_size] = item;
            batch_size++;
        } else {
            /* Non-RX work - process immediately */
            switch (item.type) {
                case 2: /* TX_COMPLETE */
                    handle_tx_complete(device_id, item.data1);
                    worker_stats.tx_processed++;
                    break;
                case 3: /* ERROR */
                    handle_device_error(device_id, item.data1, item.data2);
                    worker_stats.errors_processed++;
                    break;
            }
            processed++;
        }
    }
    
    /* Process RX batch for better cache behavior */
    for (int i = 0; i < batch_size; i++) {
        if (handle_rx_packet(device_id, rx_items[i].data1, rx_items[i].ptr) == 0) {
            worker_stats.rx_processed++;
            processed++;
        }
    }
    
    /* Schedule bulk refill if we processed many packets */
    if (batch_size >= RX_BATCH_THRESHOLD) {
        schedule_rx_refill(device_id);
    }
    
    worker_stats.total_processed += processed;
    return processed;
}

/**
 * Worker with batch optimization
 */
int worker_process_batched(void)
{
    int total_processed = 0;
    
    for (uint8_t device_id = 0; device_id < 4; device_id++) {
        if (workqueue_has_work(device_id)) {
            total_processed += process_rx_batch(device_id, MAX_WORK_BUDGET / 4);
        }
    }
    
    if (total_processed == 0) {
        worker_stats.empty_polls++;
    }
    
    return total_processed;
}

/**
 * Worker statistics and monitoring
 */

/**
 * Get worker statistics
 */
void worker_get_stats(struct worker_stats *stats)
{
    if (!stats) return;
    
    stats->total_processed = worker_stats.total_processed;
    stats->rx_processed = worker_stats.rx_processed;
    stats->tx_processed = worker_stats.tx_processed;
    stats->errors_processed = worker_stats.errors_processed;
    stats->budget_exceeded = worker_stats.budget_exceeded;
    stats->empty_polls = worker_stats.empty_polls;
    stats->max_burst_size = worker_stats.max_burst_size;
    stats->avg_burst_size = worker_stats.avg_burst_size;
    
    /* Calculate efficiency metrics */
    if (worker_stats.empty_polls + worker_stats.total_processed > 0) {
        stats->efficiency = (worker_stats.total_processed * 100) / 
                          (worker_stats.empty_polls + worker_stats.total_processed);
    } else {
        stats->efficiency = 100;
    }
    
    /* Calculate load balance across work types */
    uint32_t work_items = worker_stats.rx_processed + worker_stats.tx_processed + 
                         worker_stats.errors_processed;
    if (work_items > 0) {
        stats->rx_percentage = (worker_stats.rx_processed * 100) / work_items;
        stats->tx_percentage = (worker_stats.tx_processed * 100) / work_items;
        stats->error_percentage = (worker_stats.errors_processed * 100) / work_items;
    }
}

/**
 * Reset worker statistics
 */
void worker_reset_stats(void)
{
    memset(&worker_stats, 0, sizeof(worker_stats));
}

/**
 * Worker health check
 */
int worker_health_check(void)
{
    /* Check for excessive budget overruns */
    if (worker_stats.budget_exceeded > worker_stats.total_processed / 10) {
        return -1;  /* Budget too small or system overloaded */
    }
    
    /* Check for efficiency problems */
    uint32_t total_calls = worker_stats.empty_polls + worker_stats.total_processed;
    if (total_calls > 100) {  /* Enough samples */
        uint8_t efficiency = (worker_stats.total_processed * 100) / total_calls;
        if (efficiency < 30) {
            return -2;  /* Too many empty polls */
        }
    }
    
    /* Check for error rate */
    uint32_t work_items = worker_stats.rx_processed + worker_stats.tx_processed + 
                         worker_stats.errors_processed;
    if (work_items > 100) {  /* Enough samples */
        uint8_t error_rate = (worker_stats.errors_processed * 100) / work_items;
        if (error_rate > 5) {
            return -3;  /* High error rate */
        }
    }
    
    return 0;  /* Healthy */
}

/**
 * Integration points for packet handlers
 */

/**
 * Default RX packet handler
 * This should be overridden by the actual implementation
 */
int __attribute__((weak)) handle_rx_packet(uint8_t device_id, uint16_t length, void *buffer)
{
    /* Default implementation - just count the packet */
    LOG_DEBUG("RX packet: device %u, length %u, buffer %p", 
             device_id, length, buffer);
    return 0;
}

/**
 * Default TX completion handler
 */
int __attribute__((weak)) handle_tx_complete(uint8_t device_id, uint16_t descriptor_id)
{
    LOG_DEBUG("TX complete: device %u, descriptor %u", device_id, descriptor_id);
    return 0;
}

/**
 * Default error handler
 */
int __attribute__((weak)) handle_device_error(uint8_t device_id, uint16_t error_code, uint32_t error_data)
{
    LOG_WARNING("Device error: device %u, code 0x%04X, data 0x%08lX", 
               device_id, error_code, error_data);
    return 0;
}

/**
 * Default RX refill scheduler
 */
int __attribute__((weak)) schedule_rx_refill(uint8_t device_id)
{
    LOG_DEBUG("RX refill scheduled for device %u", device_id);
    return 0;
}